
```markdown
# Assignment 2 ‚Äì Language Model Training (Underfit, Overfit & Best Fit)

This project demonstrates three different training behaviors of a simple **Neural Language Model** built using **PyTorch**:

- **Underfitting**
- **Overfitting**
- **Best Fit (Optimal Training)**

The goal is to analyze how model complexity and training duration influence validation performance.

---



---

## üöÄ How to Run

### 1Ô∏è‚É£ Install Dependencies
```bash
pip install torch matplotlib numpy
````

### 2Ô∏è‚É£ Select the Scenario

Inside **train.py** set:

```python
EXPERIMENT = "underfit"
# or "overfit"
# or "bestfit"
```

### 3Ô∏è‚É£ Run Training

```bash
python train.py
```

---

# üìä Output Plots

## ‚úÖ Best Fit

![Best Fit](plots/loss_bestfit.png)

---

## ‚ùå Overfit

![Overfit](plots/loss_overfit.png)

---

## ‚ö† Underfit

![Underfit](plots/loss_underfit.png)

---

# üß† Summary of Training Scenarios

| Scenario     | Train Loss | Validation Loss   | Interpretation                            |
| ------------ | ---------- | ----------------- | ----------------------------------------- |
| **Underfit** | High       | High              | Model is too small or trained too little  |
| **Overfit**  | Very low   | High (increasing) | Model memorizes training data             |
| **Best Fit** | Low        | Low               | Good balance of capacity & generalization |

---

# üõ† Files Description

### `model.py`

Contains the language model architecture.

### `utils.py`

Handles preprocessing, batching, and dataset splitting.

### `train.py`

Main script that:

* Loads dataset
* Trains the model
* Generates loss plots

---

# ‚ú® Contact Information

**Name:** Nikshitha Kompally
**Mobile:** +91 9701495508
**Email:** [nikshithakompally08@gmail.com](mailto:nikshithakompally08@gmail.com)
**Google Drive Submission Link:** [https://drive.google.com/drive/folders/1J_G7dBAwUTf5eAOwzpHHO1ogRTXArjMa?usp=drive_link](https://drive.google.com/drive/folders/1J_G7dBAwUTf5eAOwzpHHO1ogRTXArjMa?usp=drive_link)



---

#
